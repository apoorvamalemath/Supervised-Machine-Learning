{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmd5z4M9HMsJ"
   },
   "source": [
    "<center><h1> Homework 2 </h2>\n",
    "Supervised Machine Learning DS-5220 - Fall 2021 \n",
    "\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFHfXjoomlQO"
   },
   "source": [
    "<center>Submitted by : Apoorva Surendra Malemath </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7AayGP6quuW"
   },
   "source": [
    "<b>1.Ridge Regression  </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GUUJKzeuJXO-"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import math\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_tnc\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UV3Utro7UpBK"
   },
   "outputs": [],
   "source": [
    "def createPhiX(x,n):\n",
    "  # The function createPhix constructs a rich feature vector   \n",
    "  #x is the vector\n",
    "  #n denotes the maximum degree of x \n",
    "\n",
    "  # Appending theta0 i.e. 1 as the first column\n",
    "  x.insert(0,0, 1)\n",
    "  colX=x.iloc[: , -1] # Extracting col x\n",
    "  if(n==1):\n",
    "    return x\n",
    "  else:\n",
    "    for i in range(2,n+1):\n",
    "      colname=\"x\"+str(i)\n",
    "      x.insert(i,colname,colX**i) #appending column x with ith power\n",
    "\n",
    "  return x    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sA-tL6gzW4Xr"
   },
   "source": [
    "<b>createPhix</b> constructs a rich feature vector. The function accepts an input vector with dimenssion 1 and the value n which denotes the maximum degree of x. <br>\n",
    "\n",
    "The function performs the following actions: \n",
    "\n",
    "1. Appends $胃_{0}$ with values 1.\n",
    "2. Appends the values $x^2$, $x^3$ .. $x^n$ based on the value of n.\n",
    "3.  Return the resultant matrix $\\phi(x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RX36z7pAqBQG"
   },
   "outputs": [],
   "source": [
    "def trainModelRidge(trainX,trainY,Lambda):\n",
    "  # The function trainModel implements the closed form solution. \n",
    "  dim=trainX.shape[1]\n",
    "  I=np.identity(dim)\n",
    "  theta = np.dot(inv(np.dot(np.transpose(trainX),trainX)+np.multiply(I,Lambda))\n",
    "  ,np.dot(np.transpose(trainX), trainY))\n",
    "  \n",
    "  return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP-JdYJ2qCwc"
   },
   "source": [
    "<b>trainModelRidge</b> implements the closed form solution using the below equation: <br>\n",
    "\n",
    "$\\tilde{\\theta}$ = $(x^Tx + \\lambda I)^{-1}x^Ty$\n",
    "\n",
    "Returns the value for $\\tilde{\\theta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E7o_2fi8XIYK"
   },
   "outputs": [],
   "source": [
    "def predict(testX,thetaTilda):\n",
    "  # The function predict outputs the value fx for the test data set. \n",
    "  fx=np.dot(testX, thetaTilda)\n",
    "\n",
    "  return fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PWqKSUwXPsl"
   },
   "source": [
    "<b>predict</b> outputs the value $f(x)$ for the test data using the below equation: <br>\n",
    "$f(x) = x$$\\tilde{\\theta}$\n",
    "\n",
    "And returns the value for $f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xI4qAG7wcCHR"
   },
   "outputs": [],
   "source": [
    "def RMSE (fx,testY,n):\n",
    "  # The function calculates the mean squared error.\n",
    "  #n denotes the number of samples in the dataset\n",
    "  loss =(abs(fx-testY))**2/n\n",
    "  rmse = math.sqrt(loss.sum())\n",
    "  return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxCbBiT-nL8A"
   },
   "source": [
    "<b> Root Mean Square Error (RMSE) </b> calculates the mean squared error between the predicted value and actual value for the test dataset using the below equation: <br>\n",
    "$L=  \\sqrt{\\dfrac{\\sum_{n=1}^{n} (f(x_{i})-y_{i})}{n}} $\n",
    "\n",
    "And returns the RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EOicIsRaiw6c"
   },
   "outputs": [],
   "source": [
    "def stochasticGDRidge(trainData_SG, n,m,rho,Lambda):\n",
    "  # Implements the stochastic gradient descent on mini-batches of size m.\n",
    "  # n - number of iterations\n",
    "  # m - mini-batch size\n",
    "  # rho - learning rate\n",
    "  #Lambda - Scalar quantity\n",
    "  \n",
    "  dim=trainData_SG.shape[1]\n",
    "  thetaTilda = np.random.rand(dim-1, 1) #initializing thetaTilda to random value\n",
    "\n",
    "  I=np.identity(dim-1)\n",
    "\n",
    "  for i in range(n):\n",
    "    for j in range(m): \n",
    "      #creating random samples from the train dataset\n",
    "      miniX = trainData_SG.sample(m) \n",
    "      trainX_SG=miniX.iloc[:,0:dim-1]\n",
    "      trainY_SG=pd.DataFrame(miniX.iloc[:,dim-1])\n",
    "      thetaTilda = thetaTilda - (rho*(np.dot((np.dot(np.transpose(trainX_SG,)\n",
    "      ,trainX_SG))+np.multiply(I,Lambda),thetaTilda)-\n",
    "      (np.dot(np.transpose(trainX_SG),trainY_SG))))\n",
    "  \n",
    "  return thetaTilda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNCb79z61SzC"
   },
   "source": [
    "<b> stochasticGDRidge </b> implements the stochastic gradient descent on mini-batches of size m using the below equation:\n",
    "\n",
    "${\\theta}^t$ = $ \\theta^{t-1} - \\rho [(x^Tx + \\lambda I)\\theta ^{t-1} - x^T y]$\n",
    "\n",
    "And returns the vlaue for ${\\theta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8SvXPrqIjQPe"
   },
   "outputs": [],
   "source": [
    "def importTrainData():\n",
    "  #Importing Dataset\n",
    "  train_url='https://drive.google.com/file/d/1OaTit95VrAtZLjsPoxUu77MfmL4qDWW5/view?usp=sharing'\n",
    "  url1 = 'https://drive.google.com/uc?id=' + train_url.split('/')[-2]\n",
    "  trainData = pd.read_csv(url1)\n",
    "\n",
    "  return trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UhFuCMGcyjVI"
   },
   "outputs": [],
   "source": [
    "def importTestData():\n",
    "  #Importing Dataset\n",
    "  test_url = 'https://drive.google.com/file/d/1vslpigsii2UqSSQFa3DGxsGpRcVKN7EF/view?usp=sharing'\n",
    "  url2 = 'https://drive.google.com/uc?id=' + test_url.split('/')[-2]\n",
    "  testData = pd.read_csv(url2)\n",
    "\n",
    "  return testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MB4taVoCx6rU"
   },
   "outputs": [],
   "source": [
    "def splitXY(Data):\n",
    "  #Seperating x and y in for train data\n",
    "  XData = Data['x']\n",
    "  YData = Data['y']\n",
    "\n",
    "  #converting series datatype to pandas dataframe\n",
    "  XData = XData.to_frame()\n",
    "  YData = YData.to_frame()\n",
    "\n",
    "  return XData,YData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HH19YZ7xX02j"
   },
   "source": [
    "\n",
    "<b>(a)  Download HW2-1 dataset. Write a code in Python that applies Ridge regression to the dataset to compute 胃 for given 位.  \\\n",
    "Implement two cases \\\n",
    "i) closed-form solution </b> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9MGkCrJ5yv34"
   },
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "trainData_P1= importTrainData()\n",
    "testData_P1=importTestData()\n",
    "\n",
    "#Seperating x and y in for train data\n",
    "trainX_P1, trainY_P1 = splitXY(trainData_P1)\n",
    "\n",
    "#Seperating x and y in for test data\n",
    "testX_P1, testY_P1 = splitXY(testData_P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWBz3BZiXdtD",
    "outputId": "550a36af-ba4b-4055-c6c2-d4c47049e90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX matrix (()): \n",
      "   0         x\n",
      "0  1 -2.752646\n",
      "1  1  2.991095\n",
      "2  1  2.013596\n",
      "3  1 -0.370822\n",
      "4  1  0.325225\n"
     ]
    }
   ],
   "source": [
    "#creating Phi(x) matrix for train data\n",
    "trainX_P1=createPhiX(trainX_P1,1) \n",
    "print(\"trainX matrix (()): \")\n",
    "print(trainX_P1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMLnyj1tZTO8",
    "outputId": "3d6b0daf-7c76-4fdc-be0d-5d3be255957a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testX matrix (()):\n",
      "   0         x\n",
      "0  1  1.068146\n",
      "1  1 -2.698995\n",
      "2  1  2.332665\n",
      "3  1 -3.375883\n",
      "4  1 -2.727457\n"
     ]
    }
   ],
   "source": [
    "testX_P1=createPhiX(testX_P1,1) #creating Phi(x) matrix for test data\n",
    "print(\"testX matrix (()):\")\n",
    "print(testX_P1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9VrrZCJdeRc",
    "outputId": "d8fc5295-261d-4768-c0cd-24916cd32153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetaTilda ():\n",
      "[[ 11.81000411]\n",
      " [113.72543565]]\n"
     ]
    }
   ],
   "source": [
    "Lambda=1\n",
    "thetaTilda_P1=trainModelRidge(trainX_P1,trainY_P1,Lambda) \n",
    "# Train the model to generate thetaTilda by applying the closed form solution \n",
    "#for Ridge Regression\n",
    "print(\"thetaTilda ():\")\n",
    "print(thetaTilda_P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvbWrae0decc",
    "outputId": "066c0d72-587a-44d3-addd-e4adb68f4236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for the closed form solution : 147.24833969454323\n"
     ]
    }
   ],
   "source": [
    "#Predicting fx using the model trained by the closed form solution.\n",
    "fx_P1=predict(testX_P1,thetaTilda_P1)\n",
    "#computing loss\n",
    "n=testY_P1.size\n",
    "loss_P1 = RMSE(fx_P1,testY_P1,n)\n",
    "print(\"Test Error for the closed form solution :\", loss_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5EdNiq-Xuow"
   },
   "source": [
    "<b>ii) stochastic gradient descent with mini-batch of sizem.  [20 Points]  </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xzcGvxXXUpGQ"
   },
   "outputs": [],
   "source": [
    "trainData_SG_P1=trainData_P1['x'].to_frame()\n",
    "  \n",
    "#Creating Phi(X) for training data\n",
    "trainData_SG_P1=createPhiX(trainData_SG_P1,1)\n",
    "#Appending column Y to the train data\n",
    "trainData_SG_P1['y']=trainY_P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONvCB58piber",
    "outputId": "ff19819d-4130-4b4d-854d-ad35df1bf7bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta on Applying stochastic gradient descent with mini-batch of size 10 :\n",
      "[[  8.50083888]\n",
      " [109.52448434]]\n"
     ]
    }
   ],
   "source": [
    "#Applying stochastic gradient descent with mini-batch of size 10\n",
    "thetaTilda_SG_P1=stochasticGDRidge(trainData_SG_P1,100,10,0.0001,1)\n",
    "print(\"Theta on Applying stochastic gradient descent with mini-batch of size 10 :\")\n",
    "print(thetaTilda_SG_P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Fs4gRE2t2YW",
    "outputId": "b167de6a-5275-4432-87c3-793db5c0ed83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for the stochastic gradient descent form solution : 146.5477802574614\n"
     ]
    }
   ],
   "source": [
    "#Predicting fx using the model trained by the stochastic gradient descent \n",
    "#with mini-batch of size 10 using test data.\n",
    "fx_SD_P1=predict(testX_P1,thetaTilda_SG_P1) \n",
    "#computing loss\n",
    "n=testY_P1.size\n",
    "Lambda=1\n",
    "loss = RMSE(fx_SD_P1,testY_P1,n) \n",
    "print(\"Test Error for the stochastic gradient descent form solution :\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOwWZ384e7gP"
   },
   "source": [
    "<b>(b)  Implement K-fold cross validation on the training set to obtain best regularization 位 and get optimal 胃. Consider root mean squared error(RMSE) as regression error, and report error on test samples. Report optimal 位,胃 test and training errors for K{2,10,N}, where N is number of samples. For all cases, considern-degree polynomials, andbasis function expansion (路) = [1,x,x2,...xn], try n{2,5,10}.  [10Points] </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UEumuJNWMhV6"
   },
   "outputs": [],
   "source": [
    "def kFoldValidation(nL,kL, Lambda):\n",
    "  res=pd.DataFrame(columns=['Lambda', 'n', 'k', 'Avg Error'])\n",
    "  for n in nL:\n",
    "    #iterate for each n degree\n",
    "    trainData = importTrainData()\n",
    "\n",
    "    for k in kL:\n",
    "      #iterate for each K value\n",
    "      avgError=0 #calculate average error\n",
    "      #Shuffling the train data\n",
    "      shuffledData = trainData.sample(frac=1)  \n",
    "      #splitting the train data into k parts   \n",
    "      result = np.array_split(shuffledData, k)    \n",
    "      index=list(range(0,k))\n",
    "      \n",
    "      for i in index:\n",
    "        #iterating to leave out 1, and train on the rest to the lowest error \n",
    "        # and the corresponding optimum lambda\n",
    "        testIndex=i\n",
    "        trainDF=pd.DataFrame(columns=['x','y'])\n",
    "        #creating trainDF and testDF\n",
    "        testDF=result[i]\n",
    "        trainDF=shuffledData\n",
    "        \n",
    "        testDF=testDF.reset_index(drop=True)\n",
    "        trainDF=trainDF.reset_index(drop=True)\n",
    "        temp=trainDF\n",
    "        trainDF=pd.concat([trainDF, testDF]).drop_duplicates(keep=False)\n",
    "        trainDF=trainDF.reset_index(drop=True)\n",
    "\n",
    "        #Seperating x and y in for train data\n",
    "        trainX, trainY = splitXY(trainDF)\n",
    "        #Seperating x and y in for test data\n",
    "        testX,testY= splitXY(testDF)\n",
    "        \n",
    "        trainX=createPhiX(trainX,n) #creating Phi(x) matrix for train data\n",
    "        testX=createPhiX(testX,n) #creating Phi(x) matrix for test data\n",
    "\n",
    "        # Train the model to generate thetaTilda by applying the \n",
    "        #closed form solution\n",
    "        thetaTilda=trainModelRidge(trainX,trainY,Lambda) \n",
    "        \n",
    "        #Predicting fx using the model trained by the closed form solution.\n",
    "        fx=predict(testX,thetaTilda)\n",
    "        \n",
    "        #computing loss\n",
    "        size=testY.size\n",
    "        error = RMSE(fx,testY,size)\n",
    "\n",
    "        avgError= avgError + error\n",
    "\n",
    "      avgError=avgError/k\n",
    "      new_row = {'Lambda':Lambda, 'n':n, 'k':k, 'Avg Error':avgError}\n",
    "      res = res.append(new_row, ignore_index=True)\n",
    "      \n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyNvswQKwMi_"
   },
   "source": [
    "<b> kFoldValidation </b> implements the closed form solution for ridge regression, where in the validation error returned is the average error observed over the k iterations for the given degree and Lambda. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JErAlQotvpaP",
    "outputId": "3c4e4c50-a954-43f7-8096-b483a000836a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "K Fold for Lambda  0.0001\n",
      "   Lambda     n     k   Avg Error\n",
      "0  0.0001   2.0   2.0  197.058026\n",
      "1  0.0001   2.0  10.0  186.459947\n",
      "2  0.0001   5.0   2.0   36.776985\n",
      "3  0.0001   5.0  10.0   29.466673\n",
      "4  0.0001  10.0   2.0  225.024969\n",
      "5  0.0001  10.0  10.0   34.985083\n",
      "=================================\n",
      "=================================\n",
      "K Fold for Lambda  0.001\n",
      "   Lambda     n     k   Avg Error\n",
      "0   0.001   2.0   2.0  194.200603\n",
      "1   0.001   2.0  10.0  191.068386\n",
      "2   0.001   5.0   2.0   49.753184\n",
      "3   0.001   5.0  10.0   29.799212\n",
      "4   0.001  10.0   2.0  157.146652\n",
      "5   0.001  10.0  10.0   33.465494\n",
      "=================================\n",
      "=================================\n",
      "K Fold for Lambda  0.01\n",
      "   Lambda     n     k   Avg Error\n",
      "0    0.01   2.0   2.0  202.615760\n",
      "1    0.01   2.0  10.0  190.118195\n",
      "2    0.01   5.0   2.0   35.849278\n",
      "3    0.01   5.0  10.0   29.951940\n",
      "4    0.01  10.0   2.0   32.498593\n",
      "5    0.01  10.0  10.0   34.902665\n",
      "=================================\n",
      "=================================\n",
      "K Fold for Lambda  0.1\n",
      "   Lambda     n     k   Avg Error\n",
      "0     0.1   2.0   2.0  241.895254\n",
      "1     0.1   2.0  10.0  193.831167\n",
      "2     0.1   5.0   2.0   35.307484\n",
      "3     0.1   5.0  10.0   29.406318\n",
      "4     0.1  10.0   2.0   32.121782\n",
      "5     0.1  10.0  10.0   34.470471\n",
      "=================================\n",
      "=================================\n",
      "K Fold for Lambda  1\n",
      "   Lambda     n     k   Avg Error\n",
      "0     1.0   2.0   2.0  200.276376\n",
      "1     1.0   2.0  10.0  188.414233\n",
      "2     1.0   5.0   2.0   43.657321\n",
      "3     1.0   5.0  10.0   29.174585\n",
      "4     1.0  10.0   2.0   33.090329\n",
      "5     1.0  10.0  10.0   33.819082\n",
      "=================================\n",
      "=================================\n",
      "K Fold for Lambda  3\n",
      "   Lambda     n     k   Avg Error\n",
      "0     3.0   2.0   2.0  223.507958\n",
      "1     3.0   2.0  10.0  193.350253\n",
      "2     3.0   5.0   2.0   30.089974\n",
      "3     3.0   5.0  10.0   29.985272\n",
      "4     3.0  10.0   2.0   42.050476\n",
      "5     3.0  10.0  10.0   34.707870\n",
      "=================================\n",
      "=================================\n",
      "K Fold for Lambda  10\n",
      "   Lambda     n     k   Avg Error\n",
      "0    10.0   2.0   2.0  192.291824\n",
      "1    10.0   2.0  10.0  183.330718\n",
      "2    10.0   5.0   2.0   34.787262\n",
      "3    10.0   5.0  10.0   29.739736\n",
      "4    10.0  10.0   2.0   35.266912\n",
      "5    10.0  10.0  10.0   36.326117\n",
      "=================================\n",
      "=================================\n",
      "K Fold for Lambda  100\n",
      "   Lambda     n     k   Avg Error\n",
      "0   100.0   2.0   2.0  229.234457\n",
      "1   100.0   2.0  10.0  186.382159\n",
      "2   100.0   5.0   2.0   32.208712\n",
      "3   100.0   5.0  10.0   29.291376\n",
      "4   100.0  10.0   2.0  160.513187\n",
      "5   100.0  10.0  10.0   34.563976\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "lambdaL=[ 0.0001, 0.001, 0.01, 0.1, 1, 3, 10, 100]\n",
    "kL=[2,10]\n",
    "nL=[2,5,10]\n",
    "resDF=pd.DataFrame(columns=['Lambda', 'n', 'k', 'Avg Error'])\n",
    "for l in lambdaL:\n",
    "  print(\"=================================\")\n",
    "  print(\"K Fold for Lambda \", l)\n",
    "  res=kFoldValidation(nL,kL,l)\n",
    "  print(res)\n",
    "  resDF=resDF.append(res)\n",
    "  print(\"=================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGjk58P8D1W8",
    "outputId": "e3231cd3-37b3-41f9-d0ff-c58a9e224543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum parameter setting with least average validation error:\n",
      "   Lambda    n     k  Avg Error\n",
      "3     1.0  5.0  10.0  29.174585\n"
     ]
    }
   ],
   "source": [
    "#Finding the optimal parameters setting with the least average validation error\n",
    "minimumAvgError=resDF['Avg Error'].min()\n",
    "parameters=resDF.loc[resDF['Avg Error']==minimumAvgError]\n",
    "print(\"Optimum parameter setting with least average validation error:\")\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1l6MFv-07i_Z",
    "outputId": "563716cd-0d71-4f59-e6cc-acbf1a64d6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error for the closed form solution : 25.205384260305\n"
     ]
    }
   ],
   "source": [
    "#Training and tseting the data on the optimal parameters\n",
    "n=int(parameters['n'])\n",
    "Lambda=int(parameters['Lambda'])\n",
    "\n",
    "#Importing Dataset\n",
    "trainData_P1= importTrainData()\n",
    "testData_P1=importTestData()\n",
    "\n",
    "#Seperating x and y in for train data\n",
    "trainX_P1, trainY_P1 = splitXY(trainData_P1)\n",
    "\n",
    "#Seperating x and y in for test data\n",
    "testX_P1, testY_P1 = splitXY(testData_P1)\n",
    "\n",
    "#creating Phi(x) matrix for train data \n",
    "trainX_P1=createPhiX(trainX_P1,n) \n",
    "\n",
    "#creating Phi(x) matrix for test data\n",
    "testX_P1=createPhiX(testX_P1,n) \n",
    "\n",
    "# Train the model to generate thetaTilda by applying \n",
    "#the closed form solution for Ridge Regression\n",
    "thetaTilda_P1=trainModelRidge(trainX_P1,trainY_P1,Lambda) \n",
    "\n",
    "#Predicting fx using the model trained by the closed form solution.\n",
    "fx_P1=predict(testX_P1,thetaTilda_P1)\n",
    "\n",
    "#computing loss\n",
    "n=testY_P1.size\n",
    "loss_P1 = RMSE(fx_P1,testY_P1,n)\n",
    "print(\"Test Error for the closed form solution :\", loss_P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahqsjUxLHjqm"
   },
   "source": [
    "<b>2.Logistic Regression \\\n",
    "(a)  Write  a  code  in  python  that  takes  input  a  training  dataset D={(x1,y1),...,(xN,yN)}, and its output is the weight vector w in the logistic regression model y=($w^Tx$).  [15 Points] </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4g_Ni7cUIFJ2"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  res=1/(1+ np.exp(-x))\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLZ3f9kysbJy"
   },
   "source": [
    "<b> sigmoid </b> evaluates the below mentioned expression <br>\n",
    "$L=  {\\dfrac{1}{1+e^{-x}}} $\n",
    "\n",
    "And returns the result on applying the value to the sigmoid function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Rr9aTkxnV8NZ"
   },
   "outputs": [],
   "source": [
    "def LogisticRegression(Xtrn, Y_trn, rho, epoch):\n",
    "  dim=X_trn.shape[1]\n",
    "  theta = np.random.rand(dim, 1) #initializing w to random value\n",
    "  for i in range(epoch):\n",
    "    sum=0\n",
    "    for j in range(len(X_trn)):\n",
    "      phiX=np.transpose(X_trn.iloc[j])\n",
    "      temp1=np.dot(np.transpose(theta),phiX)\n",
    "      sigmoidVal=sigmoid(temp1)\n",
    "      y=(Y_trn.iloc[j]).tolist()\n",
    "      temp3=y-sigmoidVal\n",
    "      temp4=phiX*(temp3)\n",
    "      sum=sum+temp4\n",
    "    temp5=((rho*sum).to_frame()).to_numpy()\n",
    "    theta=theta+(temp5)  \n",
    "\n",
    "  return(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFqjAlr3tPBF"
   },
   "source": [
    "<b> LogisticRegression </b> applies Gradient Descent using the below equation: <br>\n",
    "$\\theta^{t+1} = \\theta^{t} + \\rho \\sum_{i=1}^{N} \\phi (x_i)  (y_i - {\\dfrac{1}{1+e^{-\\theta^T\\phi(x_i)}}})$\n",
    "\n",
    "And returns the vlaue of theta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Dvoe_7weQhk-"
   },
   "outputs": [],
   "source": [
    "def logLoss(X_tst,Y_tst,theta):\n",
    "  z=np.dot(X_tst,theta)\n",
    "  Y_Pred=sigmoid(z)\n",
    "  logLoss= (-((Y_tst*np.log10(Y_Pred))) + (1-Y_tst)*np.log10(1-Y_Pred)).mean()\n",
    "\n",
    "  return(logLoss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8VloIrOQjz5"
   },
   "source": [
    "<b> logLoss </b> calculates using the below equation: <br>\n",
    "\n",
    "$L_{log}(y,p)=-(ylog(p) + (1-y)log(1-p))$\n",
    "\n",
    "And returns the vlaue of log loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "UIxnLL7ULQyW"
   },
   "outputs": [],
   "source": [
    "def plotDecisionBoundry(X_trn,Y_trn,theta):\n",
    "  #plotting decision boundry\n",
    "  points_x=[x/2. for x in range(-5,5)]\n",
    "\n",
    "  line_bias = theta[0]\n",
    "  line_w=[theta[1],theta[2]]\n",
    "  points_y=[line_w[0]*x + line_bias/(-1*line_w[1]) for x in points_x]\n",
    "  plt.plot(points_x, points_y, linewidth=2, color='black')\n",
    "  \n",
    "  #combining x and y to form a complete data set\n",
    "  trainData=X_trn\n",
    "  trainData['2']=Y_trn\n",
    "\n",
    "  # X = feature values, all the columns except the last column\n",
    "  X = np.array(trainData.iloc[:, :-1])\n",
    "\n",
    "  # y = target values, last column of the data frame\n",
    "  y = (trainData.iloc[:, -1])\n",
    "  # filter out the data that has class 1\n",
    "  class1 = trainData.loc[y == 1]\n",
    "  class1 = class1.drop(columns=['constant'])\n",
    "\n",
    "  # filter out the data that has class 0\n",
    "  class0 = trainData.loc[y == 0]\n",
    "  class0 = class0.drop(columns=['constant'])\n",
    "\n",
    "  #Plotting the data points\n",
    "  plt.scatter(class1.iloc[:, 0], class1.iloc[:, 1], s=10, label='Class1')\n",
    "  plt.scatter(class0.iloc[:, 0], class0.iloc[:, 1], s=10, label='Class0')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u48AAbvcCw_-"
   },
   "source": [
    "<b>(b)  Download the dataset HW2-2.  Run \\\n",
    "(1) on training data to compute w and  evaluate  on  test  set.   Plot  the  data  (use  different  colors  for data for different classes) and plot the decision boundary.  [5 Points] </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "5ZqI3rlLC4_K"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#importing data from .mat file\n",
    "!wget https://github.com/apoorvamalemath/SML/blob/main/data1.mat?raw=true \n",
    "!mv data1.mat\\?raw\\=true data1.mat\n",
    "data1 = scipy.io.loadmat('data1.mat')\n",
    "\n",
    "#Extracting data from the data1 Dictionary\n",
    "X_trn=pd.DataFrame(data1['X_trn'])\n",
    "X_tst=pd.DataFrame(data1['X_tst'])\n",
    "\n",
    "Y_trn=pd.DataFrame(data1['Y_trn'])\n",
    "Y_tst=pd.DataFrame(data1['Y_tst'])\n",
    "\n",
    "#creating Phi(x) matrix for train data and test data by Appending '1' column \n",
    "X_trn.insert(0,'constant',1)\n",
    "X_tst.insert(0,'constant',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mPs6JeODld6",
    "outputId": "1d60c975-a110-4676-a68b-20653e274ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta using the logistic Regression: \n",
      "[[ 0.34654432]\n",
      " [ 1.98144223]\n",
      " [-1.02359093]]\n"
     ]
    }
   ],
   "source": [
    "#Fitting the logistic Regression Model\n",
    "rho=0.0001\n",
    "epoch=1000\n",
    "theta=LogisticRegression(X_trn,Y_trn, rho, epoch)\n",
    "print(\"Theta using the logistic Regression: \")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "WxcGzYA3F4Tc",
    "outputId": "f362ef25-44cf-4739-d7ef-b4f0dd719c1c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the decision boundry \n",
    "plotDecisionBoundry(X_trn, Y_trn,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DePKv3rINMJO",
    "outputId": "23561c67-d266-45b5-d765-00fd66156533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss :  0.002132414995965543\n"
     ]
    }
   ],
   "source": [
    "#Computing Log loss to evaluate on test data\n",
    "loss=logLoss(X_tst,Y_tst, theta)\n",
    "print(\"Log loss : \", float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAgyxGS5J-p8"
   },
   "source": [
    "<b>(c)  Repeat (2) for HW2-3. Explain the differences between two datasetsand justify your results / observations.  [5 Points] </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "yLiVrBeggxhP"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#importing data from .mat file\n",
    "!wget https://github.com/apoorvamalemath/SML/blob/main/data2.mat?raw=true \n",
    "!mv data2.mat\\?raw\\=true data2.mat\n",
    "data2 = scipy.io.loadmat('data2.mat')\n",
    "\n",
    "#Extracting data from the data1 Dictionary\n",
    "X_trn=pd.DataFrame(data2['X_trn'])\n",
    "X_tst=pd.DataFrame(data2['X_tst'])\n",
    "\n",
    "Y_trn=pd.DataFrame(data2['Y_trn'])\n",
    "Y_tst=pd.DataFrame(data2['Y_tst'])\n",
    "\n",
    "#creating Phi(x) matrix for train data and test data by Appending '1' column \n",
    "X_trn.insert(0,'constant',1)\n",
    "X_tst.insert(0,'constant',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9zovIi3iND3",
    "outputId": "e3e1ba90-1689-4498-e1ec-a70a0d9d3baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta using the logistic Regression: \n",
      "[[ 0.39161236]\n",
      " [ 2.17102042]\n",
      " [-0.35971089]]\n"
     ]
    }
   ],
   "source": [
    "#Fitting the logistic Regression Model\n",
    "rho=0.0001\n",
    "n=1000\n",
    "theta=LogisticRegression(X_trn,Y_trn, rho,n)\n",
    "print(\"Theta using the logistic Regression: \")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "80aUohrYiTFW",
    "outputId": "b341b759-157b-4e97-d355-31af4ffa22cf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the decision boundry \n",
    "plotDecisionBoundry(X_trn, Y_trn,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxtwyf_zRhSF",
    "outputId": "07eb23fd-fa82-4e7d-f519-b791ba446c2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss :  0.02831373338731127\n"
     ]
    }
   ],
   "source": [
    "#Computing Log loss to evaluate on test data\n",
    "loss=logLoss(X_tst,Y_tst, theta)\n",
    "print(\"Log loss : \", float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_YGX0ngX3f7"
   },
   "source": [
    " On comparing the above two plots, it is observered that in data1 there are just 2 points that are very close to the decision boundry. However, they are still getting classified in their respective classes. On observing data2, the classes overlap a little, it is seen that few points close to the decision boundry are getting classified in the wrong class. And log loss for data1 is lower than the log loss observed for data2.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
